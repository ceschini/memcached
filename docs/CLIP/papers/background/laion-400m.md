# LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs

An open-source initiative to replicate openAI private dataset used for training of CLIP.

- [Clip front](https://rom1504.github.io/clip-retrieval/?back=https%3A%2F%2Fknn.laion.ai&index=laion_400m&useMclip=false&query=person) - Web page with image/text queries using CLIP embedding to retrieve LAION-400M images.
- [Clip retrieval](https://github.com/rom1504/clip-retrieval) - back-end of the above Clip front-end, computes embedding to create a clip semantic search system.
