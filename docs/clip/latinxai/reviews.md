# LatinxAI Submission Reviews

## Reviewer 1

1. lacks a strong theoretical grounding or principled framework to explain why certain models or prompt strategies reduce bias
2. The work assumes a binary gender paradigm and doesnâ€™t discuss non-binary representations, which limits the scope of its fairness contributions.
3. the exact choice of k and its effect on overfitting or generalization is underexplored
4. while the work shows that data scaling is less effective than expected, the discussion does not deeply probe into data content or annotation quality

## Reviewer 2

To improve the quality of the manuscript is suggested to the authors:  
  
1. Clarify in the introduction the contributions of the work.  
2. Split the related work section into subsections.  
3. Rename section 3 "our methodology", for example to " evaluation methodology". Also, include a figure showing the model's assessment methodology, since it is not clear completely the process used to retrain the evaluated models.  
4. Some of the conclusions are more limitations of the study, thus, it is suggested to include a limitation section.  
5. Rephrase the conclusion section by including clear/concrete future works or research lines to improve the generalization of the study about social models for vision language models.

## Reviewer 4

1. Explore the potential impact of different languages on model bias.
2. Explore the unexpected performance difference between the Huge and Giant mode lversions.
3. Include absolute numbers alongside the percentages in the Conclusions.