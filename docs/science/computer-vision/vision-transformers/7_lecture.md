# Lecture about vision transformers

## Topics

- Attention mechanism
- Multi-head Self Attention module
- Linear embedding layer
